{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e366f87-0352-4a72-b089-990170dea7cd",
   "metadata": {},
   "source": [
    "![Top <](./images/watsonxdata.png \"watsonxdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f8c21-574e-4877-b66b-e6712b963f10",
   "metadata": {},
   "source": [
    "# Convert CSV to Parquet\n",
    "\n",
    "This sample code takes an input CSV file and converts to Parquet format. At the same time it generates the SQL required to catalog the table in the watsonx.data database. \n",
    "\n",
    "Update the filenames below to reflect the CSV input file and the name of the parquet file that it generates. Note that this code assumes that there is a header for the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d64f3-67f6-483b-8414-a11b2852302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "csv_in      = \"/sampledata/csv/taxi/taxi.csv\"\n",
    "parquet_out = \"/tmp/taxi.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e21ec-46ad-4d10-add5-fa904c816be8",
   "metadata": {},
   "source": [
    "Enter the details of the catalog, schema, table name and the location of the S3 bucket that contains the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be740fe-04e1-4f00-b5f2-4b8ffa967867",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog     = \"hive_data\"\n",
    "schema      = \"ontime\"\n",
    "table       = \"ontime\"\n",
    "bucket      = \"s3a://hive-bucket/ontime/ontime\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728402fa-3b7a-4c9a-866f-cc9170ccd877",
   "metadata": {},
   "source": [
    "This code makes some assumptions about the data type conversion that will be used when taking the CSV file and creating the parquet file. You may need to adjust the column types when the SQL is generated. Note that this code does not execute the SQL that is produced. The assumption is that you will take the generated SQL and run it in the watsonx.data UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7cd61-8f54-4380-a71a-65ca5ab3005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValue = pd.read_csv(csv_in,na_values=\"-\")\n",
    "dfValue = dfValue.fillna(0)\n",
    "\n",
    "columns = dict(dfValue.dtypes)\n",
    "column_to_type = {}\n",
    "\n",
    "for column in columns:\n",
    "\n",
    "    datatype = str(columns[column])\n",
    "    datatype = datatype.upper()\n",
    "\n",
    "    if (datatype == \"OBJECT\"):\n",
    "        type = \"string\" \n",
    "    elif (datatype == \"INT64\"):\n",
    "        type = \"int64\"\t\t\n",
    "    elif (datatype == \"FLOAT64\"):\n",
    "        type = \"double\"\n",
    "    elif (\"DATETIME64\" in datatype):\n",
    "        type = \"timestamp\"\n",
    "    elif (datatype == \"BOOL\"):\n",
    "        type = \"binary\"\n",
    "    else:\n",
    "        type = \"string\"  \n",
    "\n",
    "    column_to_type.update({column:type})\n",
    "\n",
    "dfValue = dfValue.astype(column_to_type)\n",
    "dfValue.to_parquet(parquet_out)\n",
    "\n",
    "sql = f'CREATE TABLE IF NOT EXISTS \"{catalog}\".\"{schema}\".\"{table}\" (\\n'\n",
    "first_line = True\n",
    "for key in column_to_type.keys():\n",
    "    if (first_line == False):\n",
    "        sql = sql + \",\\n\"\n",
    "    first_line = False\n",
    "    column_definition = f'\"{key}\" {column_to_type[key]}'\n",
    "    sql = sql + column_definition\n",
    "sql = sql + '\\n)\\n'\n",
    "sql = sql + f\"WITH (format='PARQUET',external_location='{bucket}');\"\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fc16d-3cbd-4313-99af-94ce268f962a",
   "metadata": {},
   "source": [
    "We can double check to see that the parquet file has been produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286fee0-e4cc-4805-9e74-e35457e4af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%system ls -al {parquet_out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e9bb8-d355-4717-b417-c88261b6e5c5",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2025, George Baklarz [baklarz@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
